{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac786741-17a5-495b-afb4-f5513ad1db3d",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "\n",
    "Anomaly detection is the process of identifying data points, items, or events that deviate significantly from the norm or expected pattern.\n",
    "\n",
    " These anomalies can be considered as outliers, noise, or exceptions.   \n",
    "\n",
    "The purpose of anomaly detection is to:\n",
    "\n",
    "Identify unusual patterns: Detect deviations from normal behavior that might indicate potential problems or opportunities.   \n",
    "Prevent fraud: Detect fraudulent activities like credit card fraud or insurance claims.   \n",
    "System health monitoring: Identify system failures or performance issues.\n",
    "Network intrusion detection: Detect malicious activities in network traffic.\n",
    "Quality control: Identify defective products or manufacturing errors.   \n",
    "\n",
    "\n",
    "Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "\n",
    "Anomaly detection often faces the following challenges:\n",
    "\n",
    "Defining normality: Determining what constitutes normal behavior can be subjective and depends on the specific context.\n",
    "Imbalanced data: Anomalies are typically rare, leading to imbalanced datasets which can affect model performance.\n",
    "Evolving patterns: Normal behavior can change over time, requiring adaptive models.\n",
    "High dimensionality: In many real-world applications, data has a large number of features, making it difficult to identify anomalies.\n",
    "Noisy data: Real-world data often contains noise, which can hinder anomaly detection.   \n",
    "\n",
    "\n",
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "\n",
    "Unsupervised Anomaly Detection\n",
    "Assumes no prior knowledge of anomalies.\n",
    "Learns the normal patterns from the data itself.   \n",
    "Identifies data points that deviate significantly from the learned pattern.\n",
    "Commonly used when labeled data is scarce or unavailable.   \n",
    "Supervised Anomaly Detection\n",
    "Requires labeled data with both normal and anomalous instances.   \n",
    "Builds a model to classify new data points as normal or anomalous.\n",
    "Generally achieves higher accuracy but relies on availability of labeled data.   \n",
    "\n",
    "\n",
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "Anomaly detection algorithms can be categorized into several types:\n",
    "\n",
    "Statistical methods: Based on statistical properties of data, such as Z-score, IQR, and density-based methods.   \n",
    "Machine learning-based methods: Employ various machine learning techniques, including clustering, classification, and neural networks.\n",
    "Information-theoretic methods: Utilize information theory concepts to identify anomalies.\n",
    "Spectral methods: Employ techniques from spectral graph theory.\n",
    "\n",
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "Distance-based anomaly detection methods assume:   \n",
    "\n",
    "Data points are represented in a metric space.\n",
    "Anomalies are data points that are far away from their neighbors.   \n",
    "The density of normal data points is higher than the density of anomalous points.\n",
    "\n",
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "Local Outlier Factor (LOF) is a density-based anomaly detection algorithm. It computes anomaly scores based on the local density of data points.   \n",
    "\n",
    "k-nearest neighbors: For each data point, identify its k nearest neighbors.\n",
    "Reachability distance: Calculate the reachability distance of each neighbor to the data point.   \n",
    "Local reachability density: Compute the average reachability distance of the data point to its k nearest neighbors.   \n",
    "Local outlier factor: Calculate the ratio of the average local reachability density of a data point to the average local reachability density of its k nearest neighbors. A higher LOF score indicates a higher likelihood of being an outlier.   \n",
    "\n",
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "Isolation Forest is an anomaly detection algorithm based on random decision trees. The key parameters are:   \n",
    "\n",
    "Number of trees: The number of decision trees in the forest.\n",
    "Subsampling size: The number of data points randomly selected for each tree.\n",
    "Contamination: The estimated proportion of anomalies in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f477378-fcfd-4014-bb70-ab41e0be0f4a",
   "metadata": {},
   "source": [
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score\n",
    "using KNN with K=10?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2efba52-d98f-4396-8566-7c151779d87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_anomaly_score(neighbors_within_radius, total_neighbors, k):\n",
    "    \"\"\"\n",
    "    Compute the anomaly score using KNN.\n",
    "    \n",
    "    Parameters:\n",
    "    - neighbors_within_radius (int): Number of neighbors of the same class within the given radius.\n",
    "    - total_neighbors (int): Total number of neighbors considered (including those outside the radius).\n",
    "    - k (int): Number of neighbors considered for anomaly scoring.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Anomaly score.\n",
    "    \"\"\"\n",
    "    # If there are fewer neighbors within the radius than the total number of neighbors, the score needs adjustment\n",
    "    if total_neighbors < k:\n",
    "        total_neighbors = k\n",
    "    \n",
    "    # Calculate the proportion of neighbors of the same class within the radius\n",
    "    proportion_within_radius = neighbors_within_radius / k\n",
    "    \n",
    "    # Calculate the anomaly score (simple ratio-based scoring)\n",
    "    anomaly_score = 1 - proportion_within_radius\n",
    "    return anomaly_score\n",
    "\n",
    "# Parameters\n",
    "neighbors_within_radius = 2\n",
    "k = 10  # Number of neighbors for KNN\n",
    "\n",
    "# Compute anomaly score\n",
    "anomaly_score = compute_anomaly_score(neighbors_within_radius, k, k)\n",
    "print(f'Anomaly Score: {anomaly_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682b38a2-26d0-47d3-9c2c-e41f9bf7b5d2",
   "metadata": {},
   "source": [
    "\n",
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the\n",
    "anomaly score for a data point that has an average path length of 5.0 compared to the average path\n",
    "length of the trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3caf14a-17ea-4575-b7df-bb1d09364a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Score: 0.9980\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def average_path_length(n):\n",
    "    \"\"\"\n",
    "    Calculate the average path length for a dataset of size n.\n",
    "    \n",
    "    Parameters:\n",
    "    - n (int): Number of data points in the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Average path length.\n",
    "    \"\"\"\n",
    "    # Euler-Mascheroni constant\n",
    "    gamma = 0.5772\n",
    "    if n <= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * (np.log2(n - 1) + gamma * (n - 1) / 2)\n",
    "\n",
    "def compute_anomaly_score(E_x, n):\n",
    "    \"\"\"\n",
    "    Compute the anomaly score using Isolation Forest.\n",
    "    \n",
    "    Parameters:\n",
    "    - E_x (float): Average path length of the data point.\n",
    "    - n (int): Number of data points in the dataset.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Anomaly score.\n",
    "    \"\"\"\n",
    "    # Calculate average path length for the dataset\n",
    "    c_n = average_path_length(n)\n",
    "    \n",
    "    # Compute the anomaly score\n",
    "    anomaly_score = 2 ** (-E_x / c_n)\n",
    "    return anomaly_score\n",
    "\n",
    "# Parameters\n",
    "n = 3000  # Number of data points\n",
    "E_x = 5.0  # Average path length of the data point\n",
    "\n",
    "# Compute anomaly score\n",
    "anomaly_score = compute_anomaly_score(E_x, n)\n",
    "print(f'Anomaly Score: {anomaly_score:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
